{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "jqRIbJrb0FBt"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMN/+GEMta5QLFJaZhV6Zt+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g-e-mm/Alzheimers-predictor-cnn/blob/main/Capstone_Project_2_Gem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Alzheimer's Disease Predictor using CNN**\n",
        "---\n",
        "Done by,<br> Gem Barnaba as a part of PGP Data Analytics with ML course from IMARTICUS Learning<br> for the purpose of Capstone Project 2"
      ],
      "metadata": {
        "id": "5gcK0JyHcqUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APPROACH TO THE PROJECT**<br><br>\n",
        "**1.** [**Project Objectives and Dataset Info**](#Section1)<br>\n",
        "**2.** [**Loading Dataset and Libraries**](#Section2)<br>\n",
        "**3.** [**Data Pre-Processing**](#Section3)<br>\n",
        "**4** [**Model Building**](#Section4)<br>\n",
        "  - **4.1** [**Declaring the Model and Layers**](#Section401)\n",
        "  - **4.2** [**Compiling the Model**](#Section402)\n",
        "  - **4.3** [**Fitting the Model**](#Section403)\n",
        "\n",
        "**5.** [**Prediction using and evaluating the Model**](#Section5)<br>\n",
        "**6.** [**Deployment using Gradio**](#Section6)<br>\n",
        "**7.** [**Footnote**](#Section7)<br>"
      ],
      "metadata": {
        "id": "QGbAHF0vQOEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section1></a>\n",
        "# **1. Project Objectives and Dataset Info**\n",
        "---"
      ],
      "metadata": {
        "id": "jqRIbJrb0FBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Context:**<br>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- **Alzheimer's Disease (AD)**: AD is the most common form of dementia, causing progressive brain cell damage, memory loss, and cognitive decline. It's expected to affect 152 million people by 2050, with annual treatment costs of 1 trillion USD. Early diagnosis can slow its progression, but AD datasets are limited and imbalanced, often leading to misclassification of early symptoms as \"No Alzheimer's.\"\n",
        "\n",
        "- **GAN-based Solutions**: Conventional methods for addressing class imbalance are not optimal. GANs, particularly WGANs-GP, can generate new MRI images, improving classifier performance on unseen data. This helps mitigate bias and class imbalance in AD datasets.\n",
        "\n",
        "- **Improved Performance**: Synthetic MRIs generated using WGANs-GP improved minority class accuracy by 91.4%, with only a 1% drop for the majority class. The balanced dataset achieved 99% accuracy, outperforming traditional methods like SMOTE and image augmentation.\n",
        "\n",
        "- **High-Quality Synthetic MRIs**: The synthetic MRIs showed strong metrics, with an FID score of 0.13, SSIM of 0.97, PSNR of 32 dB, and Sharpness Difference of 0.04, indicating they closely match the quality of original MRIs.\n",
        "\n",
        "**Dataset Description:**\n",
        "\n",
        "---\n",
        "\n",
        "- **Dataset Composition**: The dataset includes a mix of real and synthetic axial MRIs, created to address the class imbalance in the original Kaggle Alzheimer's dataset. The dataset features four categories: \"No Impairment\" (100 patients), \"Very Mild Impairment\" (70 patients), \"Mild Impairment\" (28 patients), and \"Moderate Impairment\" (2 patients). Each patient's brain was sliced into 32 horizontal axial MRIs.\n",
        "\n",
        "- **MRI Acquisition**: The MRI images were captured using a 1.5 Tesla MRI scanner with a T1-weighted sequence. The images have a 128x128 pixel resolution in “.jpg” format, and all have been pre-processed to remove the skull.\n",
        "\n",
        "- **Synthetic MRI Considerations**: The synthetic MRIs were not verified by a radiologist, so the dataset may not fully represent real-world patient symptoms. However, there are no privacy concerns since the synthetic MRIs do not resemble actual patients."
      ],
      "metadata": {
        "id": "Ezfc0TOma0M0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section2></a>\n",
        "# **2. Loading Datasets and Libraries**\n",
        "---"
      ],
      "metadata": {
        "id": "t0jytB--b2NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D,Activation, Flatten, Dense, Dropout, BatchNormalization, LSTM, ConvLSTM2D\n",
        "from keras.losses import categorical_crossentropy\n"
      ],
      "metadata": {
        "id": "beR6a-ecdIgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet"
      ],
      "metadata": {
        "id": "TIYiYXET8bEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "zc3oaDct8f3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(5638)\n",
        "random.seed(5638)"
      ],
      "metadata": {
        "id": "t15974Qzh6oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip AD_Prediction.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ot_qJ-XErZPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_data(train_dir, test_dir, target_size=(128, 128), batch_size=32):\n",
        "  \"\"\"Loads image data from the specified directories and returns training and testing generators.\n",
        "\n",
        "  Args:\n",
        "    train_dir: The directory containing the training data.\n",
        "    test_dir: The directory containing the testing data.\n",
        "    target_size: The desired image size.\n",
        "    batch_size: The desired batch size.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of two ImageDataGenerator objects: train_generator and test_generator.\n",
        "  \"\"\"\n",
        "\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True)\n",
        "\n",
        "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size=target_size,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  test_generator = test_datagen.flow_from_directory(\n",
        "      test_dir,\n",
        "      target_size=target_size,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  return train_generator, test_generator\n",
        "\n",
        "train_dir = '/content/Combined Dataset/train'\n",
        "test_dir = '/content/Combined Dataset/test'\n",
        "train_df, test_df = load_image_data(train_dir, test_dir)"
      ],
      "metadata": {
        "id": "nKndRz5B79AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section3></a>\n",
        "# **3. Data Preprocessing**\n",
        "---"
      ],
      "metadata": {
        "id": "znCSc9Ftb7lD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {value: key for key, value in train_df.class_indices.items()}\n",
        "\n",
        "print(\"Label in in train and validation datasets\\n\")\n",
        "\n",
        "for key, value in labels.items():\n",
        "    print(f'{key} : {value}')"
      ],
      "metadata": {
        "id": "U4gH-cEi8QnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_images(dataframe, num_images=16):\n",
        "  \"\"\"Displays a specified number of images from the dataframe along with their labels.\n",
        "\n",
        "  Args:\n",
        "    dataframe: The dataframe containing image filenames and labels.\n",
        "    num_images: The number of images to display.\n",
        "  \"\"\"\n",
        "\n",
        "  # Get a batch of images and labels using next()\n",
        "  batch_x, batch_y = next(dataframe) # Use next() with the iterator\n",
        "\n",
        "  plt.figure(figsize=(16, 8))\n",
        "  for i in range(min(num_images, dataframe.batch_size)):\n",
        "      img = batch_x[i]\n",
        "      # Get the index of the predicted class (highest probability)\n",
        "      label_index = batch_y[i].argmax()\n",
        "\n",
        "      plt.subplot(4, 4, i + 1)\n",
        "      plt.imshow(img)\n",
        "      plt.title(f\"Label: {label_index}\") # Displays the predicted class index\n",
        "      plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "display_images(train_df)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Fid1oSyU-pDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section4></a>\n",
        "# **4. Model Building**\n",
        "---"
      ],
      "metadata": {
        "id": "XYA9qgvdcKAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section401></a>\n",
        "# **4.1. Declaring the Model and Layers**"
      ],
      "metadata": {
        "id": "L_Q7z57LcO6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation='softmax')) # 4 output classes"
      ],
      "metadata": {
        "id": "JKZcXGUnAZVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "qHIu4BAb_uyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section402></a>\n",
        "# **4.2. Compiling the Model**"
      ],
      "metadata": {
        "id": "t71nXHDrcPYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = 128\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', Precision(), Recall()])"
      ],
      "metadata": {
        "id": "WpvTzF_x_01b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section403></a>\n",
        "# **4.3. Fitting the Model**"
      ],
      "metadata": {
        "id": "wY_gZz1lcPt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train_df, epochs=10, validation_data=test_df, batch_size=32)"
      ],
      "metadata": {
        "id": "iESd-NpGABI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section5></a>\n",
        "# **5. Prediction using and evaluating the model**\n",
        "---"
      ],
      "metadata": {
        "id": "VzItjpHucQCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_df)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_df.classes"
      ],
      "metadata": {
        "id": "zuzodu7h8Cy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred_classes))\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred_classes))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred_classes))"
      ],
      "metadata": {
        "id": "YSwAT3vk8A_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section6></a>\n",
        "# **6. Deployment using Gradio**\n",
        "---"
      ],
      "metadata": {
        "id": "IB8Q_D2UcQV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image):\n",
        "  \"\"\"Predicts the Alzheimer's disease case based on an input image.\n",
        "\n",
        "  Args:\n",
        "    image: The input image.\n",
        "\n",
        "  Returns:\n",
        "    The predicted case (e.g., \"No Impairment\", \"Mild Impairment\").\n",
        "  \"\"\"\n",
        "  img = image.reshape((-1, 128, 128, 3))\n",
        "  prediction = model.predict(img)\n",
        "  predicted_class_index = np.argmax(prediction)\n",
        "  predicted_class_label = labels[predicted_class_index]\n",
        "\n",
        "  return predicted_class_label"
      ],
      "metadata": {
        "id": "Ly8ymfeL8L_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install gradio\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_image,\n",
        "    inputs=gr.Image(),\n",
        "    outputs=\"text\",\n",
        "    title=\"Alzheimer's Disease Predictor\",\n",
        "    description=\"Upload an MRI image to predict the case of Alzheimer's disease.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "l_kf9aSIXSi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section7></a>\n",
        "# **7. Footnote**\n",
        "---"
      ],
      "metadata": {
        "id": "h6suy_B-clfC"
      }
    }
  ]
}